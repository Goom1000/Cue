---
phase: 09-ai-adaptation-logic
plan: 02
type: execute
wave: 2
depends_on: ["09-01"]
files_modified:
  - services/geminiService.ts
  - services/providers/geminiProvider.ts
autonomous: true

must_haves:
  truths:
    - "Gemini generates refine-mode slides from presentation-only input"
    - "Gemini generates blend-mode slides from lesson+presentation input"
    - "All modes produce teleprompter scripts with proper delimiter format"
    - "Gemini provider accepts GenerationInput or legacy (string, string[]) signature"
  artifacts:
    - path: "services/geminiService.ts"
      provides: "Mode-specific system instructions and content building"
      contains: "getSystemInstructionForMode|mode.*refine|mode.*blend"
    - path: "services/providers/geminiProvider.ts"
      provides: "Updated wrapper passing GenerationInput to geminiService"
      contains: "GenerationInput"
  key_links:
    - from: "services/providers/geminiProvider.ts"
      to: "services/geminiService.ts"
      via: "calls generateLessonSlides"
      pattern: "geminiGenerateLessonSlides"
    - from: "services/providers/geminiProvider.ts"
      to: "services/aiProvider.ts"
      via: "implements AIProviderInterface"
      pattern: "implements AIProviderInterface"
---

<objective>
Implement mode-specific slide generation in GeminiProvider and geminiService.

Purpose: Ensure Gemini AI can generate appropriate content for refine and blend modes, matching the Claude implementation.

Output: Updated geminiService.ts with mode-specific prompts, geminiProvider.ts passing mode data.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-ai-adaptation-logic/09-CONTEXT.md
@.planning/phases/09-ai-adaptation-logic/09-RESEARCH.md
@.planning/phases/09-ai-adaptation-logic/09-01-SUMMARY.md

@services/aiProvider.ts
@services/geminiService.ts
@services/providers/geminiProvider.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update geminiService with mode-specific generation</name>
  <files>services/geminiService.ts</files>
  <action>
Update the generateLessonSlides function to support all three modes:

1. Import GenerationInput and GenerationMode from aiProvider:
```typescript
import { GenerationInput, GenerationMode } from './aiProvider';
```

2. Extract TELEPROMPTER_RULES as a shared constant (same content as Claude version):
```typescript
const TELEPROMPTER_RULES = `
STRICT SPEAKER NOTE RULES (TELEPROMPTER LOGIC):
The app uses a "Progressive Disclosure" system.
1. The visual bullet point appears.
2. The Student reads the bullet.
3. The Teacher (Teleprompter) adds insight.

Therefore:
- **NEVER** repeat the text that is on the slide in the speaker notes.
- **NEVER** re-summarize a point that was just made in the previous bullet.
- Each note must **ADD VALUE**: provide a concrete example, an analogy, or a "Why this matters" explanation.
- Ensure a continuous narrative flow. Note 2 must naturally follow Note 1.

FORMATTING:
The speaker notes must use "pointing_right" as a delimiter.
- Segment 0 (Intro): Set the scene before bullet 1 appears.
- Segment 1 (for Bullet 1): Elaborate on Bullet 1.
- Segment 2 (for Bullet 2): Elaborate on Bullet 2 (Do not repeat Segment 1).
- The number of "pointing_right" segments MUST be exactly (Number of Bullets + 1).
`;
```

3. Create getSystemInstructionForMode(mode: GenerationMode) function:

FRESH MODE (existing, refactored):
- Transform lesson plan into teaching slideshow
- Use images to interpret tables/charts/diagrams
- Preserve pedagogical structure
- Include Success Criteria and Differentiation slides

REFINE MODE (new):
- Extract key concepts from existing presentation images/text
- Create NEW PiPi-style slides (less text-dense)
- AI decides slide count based on content density
- May reorder for pedagogical flow
- Note visuals with "[Visual: description]"
- Output stands alone (no source references)

BLEND MODE (new):
- Analyze both lesson AND presentation
- Determine content overlap
- Add slides for uncovered lesson topics
- Standardize to PiPi style
- Flag conflicts in speakerNotes: "[Note: Sources differ on X]"

4. Update generateLessonSlides signature to accept GenerationInput:
```typescript
export const generateLessonSlides = async (
  apiKey: string,
  inputOrText: GenerationInput | string,
  pageImages: string[] = []
): Promise<Slide[]> => {
  // Normalize to GenerationInput
  const input: GenerationInput = typeof inputOrText === 'string'
    ? { lessonText: inputOrText, lessonImages: pageImages, mode: 'fresh' }
    : inputOrText;

  const systemInstruction = getSystemInstructionForMode(input.mode);
  // ... rest
}
```

5. Build contents array based on mode:
- FRESH: Lesson text + lesson images
- REFINE: Presentation text + presentation images
- BLEND: Combined text from both + images from both (limit 5 per source)

6. Use appropriate user message text per mode:
- FRESH: "Transform this formal lesson plan into a sequence of teaching slides: {lessonText}"
- REFINE: "Transform this existing presentation into PiPi-style slides: {presentationText}"
- BLEND: "Combine this lesson plan with this existing presentation into enhanced PiPi-style slides. Lesson: {lessonText} Presentation: {presentationText}"

Important: Gemini uses JSON responseSchema - keep existing schema definition (it's already correct for all modes since output format is identical).
  </action>
  <verify>TypeScript compiles: `npx tsc --noEmit`</verify>
  <done>geminiService.generateLessonSlides handles fresh/refine/blend modes with mode-specific prompts</done>
</task>

<task type="auto">
  <name>Task 2: Update GeminiProvider wrapper</name>
  <files>services/providers/geminiProvider.ts</files>
  <action>
Update the GeminiProvider to pass GenerationInput to geminiService:

1. Import GenerationInput type:
```typescript
import { GenerationInput } from '../aiProvider';
```

2. Update generateLessonSlides signature to match interface:
```typescript
async generateLessonSlides(
  inputOrText: GenerationInput | string,
  pageImages?: string[]
): Promise<Slide[]> {
  try {
    return await geminiGenerateLessonSlides(this.apiKey, inputOrText, pageImages || []);
  } catch (error) {
    throw this.wrapError(error);
  }
}
```

The normalization happens inside geminiService, so the wrapper just passes through.

Note: geminiProvider is a thin wrapper - the mode logic lives in geminiService.
  </action>
  <verify>TypeScript compiles: `npx tsc --noEmit`</verify>
  <done>GeminiProvider passes GenerationInput through to geminiService</done>
</task>

</tasks>

<verification>
1. TypeScript compiles without errors
2. Fresh mode (lesson only) with Gemini provider works exactly as before
3. Code review: getSystemInstructionForMode covers all three modes
4. Code review: TELEPROMPTER_RULES included in all mode prompts
5. Code review: contents array includes appropriate images for each mode
6. Gemini JSON responseSchema unchanged (output format identical across modes)
</verification>

<success_criteria>
- geminiService.generateLessonSlides accepts GenerationInput or legacy params
- GeminiProvider wrapper passes through to geminiService correctly
- Fresh mode behavior unchanged (backward compatible)
- Refine and blend mode system instructions include:
  - Mode-specific rules per CONTEXT.md decisions
  - TELEPROMPTER_RULES for script generation
  - Gemini-specific image handling (inlineData format)
- No new dependencies added
</success_criteria>

<output>
After completion, create `.planning/phases/09-ai-adaptation-logic/09-02-SUMMARY.md`
</output>
